---
title: "RPEXE.RPEXT"
author: "Gang Han, Yu Zhang"
date: "December 30, 2016"
output: html_document
vignette: >
  %\VignetteIndexEntry{RPEXE.RPEXT}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}
---

# 1 General Information

This reduced piecewise exponential survival software implements the likelihood ratio test procedure in Han, Schell, and Kim (2009). Inputs to the program can be either times when events/censoring occur or the vectors of total time on test and the number of events. Outputs of the programs are times of events and the corresponding p- values. The order of times and p-values is determined by a backward elimination procedure. Details about the model and implementation are given in Han, Schell, and Kim (2009). This program can run in R version 12 and above.

# 2 Inputs and Outputs
## 2.1 Inputs
This software has one driver files RPEXEv1_2.R. Inputs to RPEXEv1_2.R include

* ‘EventTime’ = time, a vector having the times of the events occurred and of
censoring. Note that ’EventTime’ is a required input.

* ‘Censor’ = censor, a vector with 0 or 1 indicating whether an observation is an event or censored. We use 0 to denote censoring and 1 to denote event. The length of time and censor are identical. Note that ’Censor’ is a required input.

* ‘CutTimes’ = cuttimes, a vector of the potential times where the piecewise exponential model is divided. Note that ‘CutTimes’ is an optional input. By default, cuttimes is a vector of times when the events occur.

* ‘Monotone’ = monotone, an indicator with values and meanings

    + 0: no monotonic assumption;
  
    + 1: assuming that the hazard is decreasing over time; 
  
    + 2: assuming that the hazard is increasing over time;
  
    + 3: assuming that the hazard is monotonic;
    
    + 4: assuming that the hazard is increasing and then decreasing;
    
    + 5: assuming that the hazard is decreasing and then decreasing;
    
    + 6: assuming that the hazard is increasing and then decreasing with the peak removed first;
    
    + 7: assuming that the hazard is decreasing and then increasing with the peak removed first;
    
    <br/>Note that ‘Monotone’ is an optional input. The default value of ‘Monotone’ is 0.
    
* 'Criticalp'  = The critical (naive) p-value cutoff where all p-values in the backward elimination that are lower than this will be regarded as being significant. The prediction of the survival probability will be made on 100 equally spaced time points within the range of the event times based on the piecewise exponential estimate determined by all the changepoints. Default == -1 (equivalent to NA).

## 2.2 Outputs
* times: times to make the cuts

* pvalues: pvalues correspond to the times

* times_c: critical times to make the cuts

* pvalues_c: critical p-values that are smaller than the

* trend: trend information

* struct:  structure information for multiple order restrictions

* changet:  change point in time for umbrella alternatives.

# 3 Example with dataset data2
## 3.1 Load data and extract variables
```{r}
library(RPEXE.RPEXT)
data(data2)
times = data2[,1]
censor = data2[,2]
group = data2[,3]

ID_nan = which(is.na(times))
times = times[-ID_nan] 
censor = censor[-ID_nan]
group = group[-ID_nan]
armsA_ID = which(group == 1)
armsB_ID = which(group == 2)
```

## 3.2 Plot the data

```{r}
# figure(1): Kaplan Meier curve of Arm A without indicating censored points 
km(times[armsA_ID], censor[armsA_ID], 0)
```
```{r}
# figure(2): Kaplan Meier curve of armA with censored points indicated
km2(times[armsA_ID], censor[armsA_ID], 1)
```
```{r}
# figure(3): Kaplan Meier curve of armB without indicating censored points 
km(times[armsB_ID], censor[armsB_ID], 0)
```
```{r}
# figure(4): Kaplan Meier curve of Arm B with censored points indicated
km2(times[armsB_ID], censor[armsB_ID], 0)
```


## 3.3 Plot the KME in the paper
```{r}
# figure(5) : Combined plot of both armA and armB 
x1 = cbind(times[armsA_ID], censor[armsA_ID])
x2 = cbind(times[armsB_ID], censor[armsB_ID])
km_combine(x1,x2)

# figure(6) : Combined plot of both armA and armB and corresponding result of Logrank test
x1 = cbind(times[armsA_ID], censor[armsA_ID])
x2 = cbind(times[armsB_ID], censor[armsB_ID])
logrank(x1,x2)
```

## 3.4 The analysis
The analysis consists of presenting the PFS rates at the two scan times, and calculating a P value based on the grouped data (Appendix). This two-point procedure, like the procedure that compares PFS rates at single time point, essentially eliminates any evaluation-time bias. However, unlike the single-point procedure, if the two scan times are chosen well, there is little risk of major power loss compared with using the actual reported progression times. In particular, we recommend choosing the two scan times to be approximately the median PFS and twice the median PFS of the control arm.

```{r}
# z score for t = median surv
(0.4828-0.4738)/sqrt(0.4828*(1-0.4828)/53+0.4738*(1-0.4738)/47)
# z score for t = 2*median surv
(0.3276-0.3796)/sqrt(0.3276*(1-0.3276)/53+0.3796*(1-0.3796)/47)
```

## 3.5 Use RPEXEv1_2 function
```{r}
# Fit the rpexe with monotonic order restriction;
pexeoutA     =  RPEXEv1_2(times[armsA_ID],censor[armsA_ID],trend = 1,criticalps=0.05)

pexeoutB     =  RPEXEv1_2(times[armsB_ID],censor[armsB_ID],trend = 1,criticalps=0.05)

# combined
pexeout = RPEXEv1_2(times,censor,trend = 1,criticalps=0.05)
```

## 3.6 Other analysis
```{r}
# calculate the ttot and n from a), 0-2.777, b), 2.777-8.959, c), 8,959-end;
#
# a), 0-2.777
returnvA=totaltest(times[armsA_ID],censor[armsA_ID]) #returnv=list(time_die,ttot,deaths),the variables owns the same length
m=dim(returnvA)[2]/3

time_dieA=returnvA[,1:m]
ttotA=returnvA[,(m+1):(2*m)]
deathsA=returnvA[,(2*m+1):3*m]

returnvB=totaltest(times[armsB_ID],censor[armsB_ID]) #returnv=list(time_die,ttot,deaths),the variables owns the same length
m=dim(returnvB)[2]/3

time_dieB=returnvB[,1:m]
ttotB=returnvB[,(m+1):(2*m)]
deathsB=returnvB[,(2*m+1):3*m]


ttotA1 = 0
ttotA2 = 0
ttotA3 = 0
dA1 = 0
dA2 = 0
dA3 = 0
for (i in 1:length(time_dieA))
{
  if ( time_dieA[i]<=2.777)
  {
    ttotA1 = ttotA1+ttotA[i]
    dA1    = dA1+deathsA[i]
  }else if (time_dieA[i]<=8.959)
  {
    ttotA2 = ttotA2+ttotA[i]
    dA2    = dA2+deathsA[i]
  } else 
  {
    ttotA3 = ttotA3+ttotA[i]
    dA3    = dA3+deathsA[i]
  }
     
}
      

ttotB1 = 0
ttotB2 = 0
ttotB3 = 0
dB1 = 0
dB2 = 0
dB3 = 0
for (i in 1:length(time_dieB))
{
  if ( time_dieB[i]<=2.777)
  {
    ttotB1 = ttotB1+ttotB[i]
    dB1    = dB1+deathsB[i]
  }else if (time_dieB[i]<=8.959)
  {
    ttotB2 = ttotB2+ttotB[i]
    dB2    = dB2+deathsB[i]
  } else 
  {
    ttotB3 = ttotB3+ttotB[i]
    dB3    = dB3+deathsB[i]
  }
}

# max(times(armsA_ID))
# max(times(armsB_ID))
# [times(armsA_ID) censor(armsA_ID)]


# test the two side hypothesis;
# first piece
result = exact_pvalue(ttotA1,ttotB1,dA1,dB1,0)
a21 = result[1]
p1 = result[2]

# second piece
result=exact_pvalue(ttotA2,ttotB2,dA2,dB2,0)
a22 = result[1]
p2 = result[2]

# third piece
result=exact_pvalue(ttotA3,ttotB3,dA3,dB3,0)
a23 = result[1]
p3 = result[2]

# first piece
result=exact_pvalue(ttotA1,ttotB1,dA1,dB1,1)
a21 = result[1]
p1 = result[2]

# second piece
result=exact_pvalue(ttotA2,ttotB2,dA2,dB2,1)
a22 = result[1]
p2 = result[2]

# third piece
result=exact_pvalue(ttotA3,ttotB3,dA3,dB3,1)
a23 = result[1]
p3 = result[2]

# first piece
result=exact_pvalue(ttotA1,ttotB1,dA1,dB1,2)
a21 = result[1]
p1 = result[2]

# second piece
result=exact_pvalue(ttotA2,ttotB2,dA2,dB2,2)
a22 = result[1]
p2 = result[2]

# third piece
result=exact_pvalue(ttotA3,ttotB3,dA3,dB3,2)
a23 = result[1]
p3 = result[2]

```

